# Taller Tercer Corte IA

## 1. Aprendizaje por Refuerzo (Reinforcement Learning)

### 1.a Â¿CÃ³mo puede un agente aprender a tomar decisiones Ã³ptimas en un entorno incierto?

Un agente de aprendizaje por refuerzo aprende a tomar decisiones Ã³ptimas
en entornos inciertos mediante un proceso iterativo de **prueba y
error** basado en los siguientes principios fundamentales:

### ğŸ”„ Proceso de Aprendizaje

-   **InteracciÃ³n continua**: El agente ejecuta acciones, observa
    estados y recibe recompensas.\
-   **RetroalimentaciÃ³n diferida**: Las consecuencias de las acciones se
    manifiestan a lo largo del tiempo.\
-   **Balance exploraciÃ³n-explotaciÃ³n**: Equilibrio entre probar nuevas
    acciones y usar conocimientos previos.

### ğŸ§  Mecanismos de Aprendizaje

``` python
# PseudocÃ³digo del proceso de aprendizaje
estado_actual = entorno.estado_inicial()
for episodio in range(max_episodios):
    acciÃ³n = polÃ­tica(estado_actual)  # DecisiÃ³n basada en polÃ­tica actual
    nuevo_estado, recompensa = entorno.ejecutar(acciÃ³n)
    actualizar_polÃ­tica(estado_actual, acciÃ³n, recompensa, nuevo_estado)
    estado_actual = nuevo_estado
```

### ğŸ“ˆ Estrategias para Incertidumbre

-   **Aprendizaje de valores**: EstimaciÃ³n de recompensas futuras
    esperadas.\
-   **ActualizaciÃ³n temporal-diferencia**: Ajuste incremental de
    predicciones.\
-   **PolÃ­ticas estocÃ¡sticas**: Probabilidades de acciÃ³n que permiten
    exploraciÃ³n.

------------------------------------------------------------------------

## 1.b Tipos de Algoritmos de Aprendizaje por Refuerzo

### ğŸ¯ MÃ©todos Basados en Valor (Value-Based)

#### Arquitectura

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Estado    â”‚   â”‚  FunciÃ³n de  â”‚   â”‚    Valor      â”‚
    â”‚    (S)      â”‚   â”‚    Valor     â”‚   â”‚    Q(s,a)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

#### Componentes

-   **FunciÃ³n Q**: Q(s,a) = recompensa esperada.\
-   **Tabla Q o red neuronal**: Donde se almacenan o aproximan valores.\
-   **PolÃ­tica Îµ-greedy**: Controla exploraciÃ³n-explotaciÃ³n.

#### Algoritmos Representativos

-   Q-Learning\
-   SARSA\
-   Deep Q-Network (DQN)

------------------------------------------------------------------------

### ğŸ¯ MÃ©todos Basados en PolÃ­tica (Policy-Based)

#### Arquitectura

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Estado    â”‚   â”‚   PolÃ­tica   â”‚   â”‚ Prob. de acciÃ³n   â”‚
    â”‚    (S)      â”‚   â”‚   Ï€(a|s)     â”‚   â”‚      Ï€(a|s)        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

#### Componentes

-   **PolÃ­tica parametrizada**\
-   **Gradiente de polÃ­tica**\
-   **SelecciÃ³n probabilÃ­stica de acciones**

#### Algoritmos Representativos

-   REINFORCE\
-   Policy Gradient\
-   Natural Policy Gradient

------------------------------------------------------------------------

### ğŸ¯ MÃ©todos Actor-CrÃ­tico (Actor-Critic)

#### Arquitectura

               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â†’ AcciÃ³n
    Estado â†’   â”‚    ACTOR     â”‚
               â”‚ (PolÃ­tica)   â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   CRÃTICO     â”‚ â† Recompensa
               â”‚   (Valor)     â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

#### Componentes

-   **Actor**: Selecciona acciones.\
-   **CrÃ­tico**: EvalÃºa el valor del estado o acciÃ³n.\
-   **Ventaja**: A(s,a) = Q(s,a) - V(s).

#### Algoritmos Representativos

-   A2C\
-   A3C\
-   PPO\
-   SAC

------------------------------------------------------------------------

## 1.c Aplicaciones en la Industria

### ğŸ­ Manufactura y LogÃ­stica

``` python
# Ejemplo: OptimizaciÃ³n de lÃ­nea de producciÃ³n
class OptimizacionProduccion:
    def tomar_decision(self, estado):
        if estado == "alta_demanda":
            return "aumentar_velocidad"
        elif estado == "falla_inminente":
            return "mantenimiento_preventivo"
```

Aplicaciones: - RobÃ³tica industrial\
- GestiÃ³n de inventarios\
- Control de calidad\
- Mantenimiento predictivo

------------------------------------------------------------------------

### ğŸ“¡ Telecomunicaciones

``` python
class RouterInteligente:
    def optimizar_ruta(self, trafico_actual, estado_red):
        return mejor_ruta
```

Aplicaciones: - GestiÃ³n de espectro\
- OptimizaciÃ³n de trÃ¡fico\
- Routing inteligente

------------------------------------------------------------------------

### ğŸš— VehÃ­culos AutÃ³nomos

-   NavegaciÃ³n\
-   Control\
-   Decisiones en tiempo real

------------------------------------------------------------------------

### âš¡ EnergÃ­a

-   Smart Grids\
-   DistribuciÃ³n Ã³ptima\
-   PredicciÃ³n de demanda

------------------------------------------------------------------------

# 2. Algoritmo Bayesiano para DetecciÃ³n de SPAM

## ğŸ“Š Datos Dado:

-   P(Spam)=0.3\
-   P(No Spam)=0.7\
-   P("gratis"\|Spam)=0.8\
-   P("gratis"\|No Spam)=0.1

------------------------------------------------------------------------

## ğŸ§® SoluciÃ³n con Bayes

### Probabilidad Total

    P("gratis") = 0.8Ã—0.3 + 0.1Ã—0.7  
                = 0.24 + 0.07  
                = 0.31

### Resultado Final

    P(Spam|"gratis") = 0.24 / 0.31 â‰ˆ 0.774

------------------------------------------------------------------------

## ğŸ’» ImplementaciÃ³n

``` python
class ClasificadorBayesSpam:
    def __init__(self):
        self.p_spam = 0.3
        self.p_no_spam = 0.7
        self.palabras_clave = {
            'gratis': {'spam': 0.8, 'no_spam': 0.1}
        }

    def calcular_probabilidad_spam(self, palabras):
        p_spam_val = self.p_spam
        p_no_spam_val = self.p_no_spam
        for palabra in palabras:
            if palabra in self.palabras_clave:
                p_spam_val *= self.palabras_clave[palabra]['spam']
                p_no_spam_val *= self.palabras_clave[palabra]['no_spam']
        total = p_spam_val + p_no_spam_val
        return p_spam_val / total

clasificador = ClasificadorBayesSpam()
print(clasificador.calcular_probabilidad_spam(['gratis']))
```

------------------------------------------------------------------------

# 3. Algoritmos MÃ¡s Usados en Academia e Industria

## ğŸ¤– Redes Neuronales (Deep Learning)

### CNN

Aplicaciones: - ImÃ¡genes\
- VisiÃ³n\
- DiagnÃ³stico mÃ©dico

------------------------------------------------------------------------

### RNN, LSTM, GRU

Aplicaciones: - Texto\
- Series temporales\
- PredicciÃ³n financiera

------------------------------------------------------------------------

## ğŸŒ³ Algoritmos de Ensamblaje

### Random Forest

### XGBoost / LightGBM / CatBoost

------------------------------------------------------------------------

## ğŸ” No Supervisado

### K-Means

### DBSCAN

------------------------------------------------------------------------

## ğŸ¦‰ ProbabilÃ­sticos

### Naive Bayes

------------------------------------------------------------------------

## ğŸ¯ MÃ¡quinas de Vectores de Soporte (SVM)

------------------------------------------------------------------------

## ğŸš€ Vanguardia

### Transformers

### Deep Reinforcement Learning

------------------------------------------------------------------------

# ğŸ“Š Tabla Comparativa

  CategorÃ­a          Algoritmos               Fortalezas        Aplicaciones
  ------------------ ------------------------ ----------------- --------------------
  Redes Neuronales   CNN, RNN, LSTM           Alta precisiÃ³n    VisiÃ³n, NLP
  Ensamblaje         Random Forest, XGBoost   Robustez          Datos tabulares
  No Supervisado     K-Means, DBSCAN          ExploraciÃ³n       SegmentaciÃ³n
  ProbabilÃ­sticos    Naive Bayes              Simple y rÃ¡pido   Spam
  Vanguardia         Transformers, RL         Estado del arte   Multimodal, robots
